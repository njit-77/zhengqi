{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "TRAIN_DATA_PATH = './data/zhengqi_train.txt'\n",
    "TEST_DATA_PATH = './data/zhengqi_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData(dataPath):\n",
    "    # load data from txt file\n",
    "    data = np.loadtxt(dataPath, dtype='float', delimiter='\\t', skiprows=1)\n",
    "    data_features = data[:, :38]#提取前38列为特征数据\n",
    "    data_labels = data[:, -1]#提取最后一列为标签数据\n",
    "    return (data_features, data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizeData(train_data, test_data):\n",
    "    mean = np.mean(train_data, axis=0)\n",
    "    std = np.std(train_data, axis=0)\n",
    "    return ((train_data - mean)/std, (test_data - mean)/std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitData(train_fetures, train_labels):\n",
    "    # split data into train and valid data\n",
    "    train_index = np.random.choice(len(train_fetures), round(len(train_fetures) * 0.8), replace=False)\n",
    "    valid_index = np.array(list(set(range(len(train_fetures))) - set(train_index)))\n",
    "    train_data_features = train_fetures[train_index]\n",
    "    valid_data_features = train_fetures[valid_index]\n",
    "    train_data_labels = train_labels[train_index]\n",
    "    valid_data_labels = train_labels[valid_index]\n",
    "    return (train_data_features, train_data_labels), (valid_data_features, valid_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreataModel():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(16, activation=tf.nn.relu, input_shape=[38]),\n",
    "        layers.Dense(16, activation=tf.nn.relu),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    optimizer = tf.train.RMSPropOptimizer(0.001)\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['mae', 'mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    (train_fetures, train_labels) = LoadData(TRAIN_DATA_PATH)\n",
    "    (test_fetures, test_labels) = LoadData(TEST_DATA_PATH)\n",
    "    (train_fetures, test_fetures) = NormalizeData(train_fetures, test_fetures)\n",
    "    (train_data_features, train_data_labels), (valid_data_features, valid_data_labels) = SplitData(train_fetures, train_labels)\n",
    "\n",
    "    model = CreataModel()\n",
    "\n",
    "    history = model.fit(train_data_features,\n",
    "                        train_data_labels,\n",
    "                        epochs=32,\n",
    "                        batch_size=64,\n",
    "                        validation_data=(valid_data_features, valid_data_labels),\n",
    "                        verbose=1)\n",
    "    \n",
    "    test_predictions = model.predict(test_fetures)\n",
    "    np.savetxt('./submit/njit_77.txt', test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2310 samples, validate on 578 samples\n",
      "Epoch 1/32\n",
      "2310/2310 [==============================] - 1s 386us/step - loss: 1.1153 - mean_absolute_error: 0.7856 - mean_squared_error: 1.1153 - val_loss: 0.9358 - val_mean_absolute_error: 0.7289 - val_mean_squared_error: 0.9358\n",
      "Epoch 2/32\n",
      "2310/2310 [==============================] - 0s 64us/step - loss: 0.6558 - mean_absolute_error: 0.6135 - mean_squared_error: 0.6558 - val_loss: 0.4609 - val_mean_absolute_error: 0.5085 - val_mean_squared_error: 0.4609\n",
      "Epoch 3/32\n",
      "2310/2310 [==============================] - 0s 67us/step - loss: 0.3390 - mean_absolute_error: 0.4339 - mean_squared_error: 0.3390 - val_loss: 0.2884 - val_mean_absolute_error: 0.4002 - val_mean_squared_error: 0.2884\n",
      "Epoch 4/32\n",
      "2310/2310 [==============================] - 0s 98us/step - loss: 0.2317 - mean_absolute_error: 0.3564 - mean_squared_error: 0.2317 - val_loss: 0.2158 - val_mean_absolute_error: 0.3344 - val_mean_squared_error: 0.2158\n",
      "Epoch 5/32\n",
      "2310/2310 [==============================] - 0s 70us/step - loss: 0.1801 - mean_absolute_error: 0.3126 - mean_squared_error: 0.1801 - val_loss: 0.1829 - val_mean_absolute_error: 0.2991 - val_mean_squared_error: 0.1829\n",
      "Epoch 6/32\n",
      "2310/2310 [==============================] - 0s 54us/step - loss: 0.1541 - mean_absolute_error: 0.2899 - mean_squared_error: 0.1541 - val_loss: 0.1631 - val_mean_absolute_error: 0.2770 - val_mean_squared_error: 0.1631\n",
      "Epoch 7/32\n",
      "2310/2310 [==============================] - 0s 79us/step - loss: 0.1409 - mean_absolute_error: 0.2761 - mean_squared_error: 0.1409 - val_loss: 0.1561 - val_mean_absolute_error: 0.2679 - val_mean_squared_error: 0.1561\n",
      "Epoch 8/32\n",
      "2310/2310 [==============================] - 0s 71us/step - loss: 0.1308 - mean_absolute_error: 0.2671 - mean_squared_error: 0.1308 - val_loss: 0.1490 - val_mean_absolute_error: 0.2595 - val_mean_squared_error: 0.1490\n",
      "Epoch 9/32\n",
      "2310/2310 [==============================] - 0s 60us/step - loss: 0.1243 - mean_absolute_error: 0.2603 - mean_squared_error: 0.1243 - val_loss: 0.1430 - val_mean_absolute_error: 0.2564 - val_mean_squared_error: 0.1430\n",
      "Epoch 10/32\n",
      "2310/2310 [==============================] - 0s 92us/step - loss: 0.1194 - mean_absolute_error: 0.2555 - mean_squared_error: 0.1194 - val_loss: 0.1419 - val_mean_absolute_error: 0.2523 - val_mean_squared_error: 0.1419\n",
      "Epoch 11/32\n",
      "2310/2310 [==============================] - 0s 62us/step - loss: 0.1157 - mean_absolute_error: 0.2508 - mean_squared_error: 0.1157 - val_loss: 0.1389 - val_mean_absolute_error: 0.2525 - val_mean_squared_error: 0.1389\n",
      "Epoch 12/32\n",
      "2310/2310 [==============================] - 0s 62us/step - loss: 0.1120 - mean_absolute_error: 0.2471 - mean_squared_error: 0.1120 - val_loss: 0.1384 - val_mean_absolute_error: 0.2528 - val_mean_squared_error: 0.1384\n",
      "Epoch 13/32\n",
      "2310/2310 [==============================] - 0s 51us/step - loss: 0.1091 - mean_absolute_error: 0.2436 - mean_squared_error: 0.1091 - val_loss: 0.1367 - val_mean_absolute_error: 0.2436 - val_mean_squared_error: 0.1367\n",
      "Epoch 14/32\n",
      "2310/2310 [==============================] - 0s 64us/step - loss: 0.1063 - mean_absolute_error: 0.2403 - mean_squared_error: 0.1063 - val_loss: 0.1345 - val_mean_absolute_error: 0.2511 - val_mean_squared_error: 0.1345\n",
      "Epoch 15/32\n",
      "2310/2310 [==============================] - 0s 88us/step - loss: 0.1036 - mean_absolute_error: 0.2382 - mean_squared_error: 0.1036 - val_loss: 0.1305 - val_mean_absolute_error: 0.2415 - val_mean_squared_error: 0.1305\n",
      "Epoch 16/32\n",
      "2310/2310 [==============================] - 0s 54us/step - loss: 0.1026 - mean_absolute_error: 0.2372 - mean_squared_error: 0.1026 - val_loss: 0.1300 - val_mean_absolute_error: 0.2438 - val_mean_squared_error: 0.1300\n",
      "Epoch 17/32\n",
      "2310/2310 [==============================] - 0s 55us/step - loss: 0.1001 - mean_absolute_error: 0.2338 - mean_squared_error: 0.1001 - val_loss: 0.1297 - val_mean_absolute_error: 0.2432 - val_mean_squared_error: 0.1297\n",
      "Epoch 18/32\n",
      "2310/2310 [==============================] - 0s 59us/step - loss: 0.0982 - mean_absolute_error: 0.2325 - mean_squared_error: 0.0982 - val_loss: 0.1316 - val_mean_absolute_error: 0.2492 - val_mean_squared_error: 0.1316\n",
      "Epoch 19/32\n",
      "2310/2310 [==============================] - 0s 87us/step - loss: 0.0977 - mean_absolute_error: 0.2319 - mean_squared_error: 0.0977 - val_loss: 0.1325 - val_mean_absolute_error: 0.2497 - val_mean_squared_error: 0.1325\n",
      "Epoch 20/32\n",
      "2310/2310 [==============================] - 0s 55us/step - loss: 0.0959 - mean_absolute_error: 0.2298 - mean_squared_error: 0.0959 - val_loss: 0.1304 - val_mean_absolute_error: 0.2493 - val_mean_squared_error: 0.1304\n",
      "Epoch 21/32\n",
      "2310/2310 [==============================] - 0s 56us/step - loss: 0.0946 - mean_absolute_error: 0.2281 - mean_squared_error: 0.0946 - val_loss: 0.1327 - val_mean_absolute_error: 0.2506 - val_mean_squared_error: 0.1327\n",
      "Epoch 22/32\n",
      "2310/2310 [==============================] - 0s 51us/step - loss: 0.0937 - mean_absolute_error: 0.2264 - mean_squared_error: 0.0937 - val_loss: 0.1299 - val_mean_absolute_error: 0.2375 - val_mean_squared_error: 0.1299\n",
      "Epoch 23/32\n",
      "2310/2310 [==============================] - 0s 64us/step - loss: 0.0922 - mean_absolute_error: 0.2252 - mean_squared_error: 0.0922 - val_loss: 0.1343 - val_mean_absolute_error: 0.2424 - val_mean_squared_error: 0.1343\n",
      "Epoch 24/32\n",
      "2310/2310 [==============================] - 0s 85us/step - loss: 0.0907 - mean_absolute_error: 0.2239 - mean_squared_error: 0.0907 - val_loss: 0.1283 - val_mean_absolute_error: 0.2378 - val_mean_squared_error: 0.1283\n",
      "Epoch 25/32\n",
      "2310/2310 [==============================] - 0s 56us/step - loss: 0.0900 - mean_absolute_error: 0.2231 - mean_squared_error: 0.0900 - val_loss: 0.1272 - val_mean_absolute_error: 0.2384 - val_mean_squared_error: 0.1272\n",
      "Epoch 26/32\n",
      "2310/2310 [==============================] - 0s 60us/step - loss: 0.0887 - mean_absolute_error: 0.2209 - mean_squared_error: 0.0887 - val_loss: 0.1282 - val_mean_absolute_error: 0.2396 - val_mean_squared_error: 0.1282\n",
      "Epoch 27/32\n",
      "2310/2310 [==============================] - 0s 63us/step - loss: 0.0884 - mean_absolute_error: 0.2209 - mean_squared_error: 0.0884 - val_loss: 0.1269 - val_mean_absolute_error: 0.2411 - val_mean_squared_error: 0.1269\n",
      "Epoch 28/32\n",
      "2310/2310 [==============================] - 0s 81us/step - loss: 0.0871 - mean_absolute_error: 0.2196 - mean_squared_error: 0.0871 - val_loss: 0.1277 - val_mean_absolute_error: 0.2431 - val_mean_squared_error: 0.1277\n",
      "Epoch 29/32\n",
      "2310/2310 [==============================] - 0s 51us/step - loss: 0.0866 - mean_absolute_error: 0.2192 - mean_squared_error: 0.0866 - val_loss: 0.1259 - val_mean_absolute_error: 0.2382 - val_mean_squared_error: 0.1259\n",
      "Epoch 30/32\n",
      "2310/2310 [==============================] - 0s 53us/step - loss: 0.0852 - mean_absolute_error: 0.2175 - mean_squared_error: 0.0852 - val_loss: 0.1273 - val_mean_absolute_error: 0.2411 - val_mean_squared_error: 0.1273\n",
      "Epoch 31/32\n",
      "2310/2310 [==============================] - 0s 68us/step - loss: 0.0853 - mean_absolute_error: 0.2180 - mean_squared_error: 0.0853 - val_loss: 0.1261 - val_mean_absolute_error: 0.2378 - val_mean_squared_error: 0.1261\n",
      "Epoch 32/32\n",
      "2310/2310 [==============================] - 0s 78us/step - loss: 0.0843 - mean_absolute_error: 0.2163 - mean_squared_error: 0.0843 - val_loss: 0.1263 - val_mean_absolute_error: 0.2401 - val_mean_squared_error: 0.1263\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
